// Each #kernel tells which function to compile; you can have many kernels
#pragma kernel InitValueBufferCS
#pragma kernel BuildIndirectDispatchArgsCS 
#pragma kernel SetupIndirectCS 

#define THREAD_SIZE_1D 8
#define THREAD_SIZE_X THREAD_SIZE_1D
#define THREAD_SIZE_Y THREAD_SIZE_X
#define THREAD_TOTAL_SZIE (THREAD_SIZE_X*THREAD_SIZE_Y)

#define TYPE_SEPARABLE 0x1      //kena use this 
#define TYPE_BURLEY    0x2      //not support 

//@ShadingCommon 
#define SHADINGMODELID_UNLIT				0
#define SHADINGMODELID_SUBSURFACE			2
#define SHADINGMODELID_PREINTEGRATED_SKIN	3
#define SHADINGMODELID_SUBSURFACE_PROFILE	5
#define SHADINGMODELID_EYE					9 
#define SHADINGMODELID_MASK					0xF		// 4 bits reserved for ShadingModelID 

// define structure here 
struct SDiffuseAndSpecular
{
    float3 Diffuse;
    float3 Specular;
};


// 0, no subsurface
// 1, Separable
// 2, Burley
// 3, Both
groupshared uint SubsurfaceTypeFlag;

uint SubsurfaceUniformParameters_MaxGroupCount;
uint4 Output_ViewportMinMax; // [0, 0, 1708, 960]
float4 Output_ExtentInverse; //[pixelSizeX, pixelSizeY, 1/pixelSizeX, 1/pixelSizeY]

static float4 InvDeviceZToWorldZTransform = float4(0.00, 0.00, 0.10, -1.00000E-08);
static float4 View_BufferSizeAndInvSize = float4(1708.00, 960.00, 0.00059, 0.00104);
static float4 SubsurfaceInput0_ExtentInverse = float4(0, 0, 0.00059, 0.00104);
static float4 SubsurfaceInput0_UVViewportBilinearMax = float4(1.00, 1.00, 0.99912, 0.99948);


//SamplerState my_point_clamp_sampler;
SamplerState pointClampSampler;
uniform Texture2D<half4>  _GBuffer0;    //Albedo
uniform Texture2D<half4>  _GBuffer1;    //Comp_M_D_R_F 
uniform Texture2D<float>  _GBuffer4;    //Depth -> pay attention, must be float, not float4 
uniform Texture2D<half4>  _CameraTexture;    //current render target  -> SubsurfaceInput0_Texture 


RWBuffer<uint> RWSeparableGroupBuffer;
RWBuffer<uint> RWIndirectDispatchArgsBuffer;
Buffer<uint> GroupBuffer;

bool UseSubsurfaceProfile(int ShadingModel)
{
    return ShadingModel == SHADINGMODELID_SUBSURFACE_PROFILE || ShadingModel == SHADINGMODELID_EYE;
}

// BufferUV
float2 ConvertGridPos2UV(uint2 GridPosition)
{
    float2 GripPositionF = float2(GridPosition);
    return Output_ExtentInverse.zw * (GripPositionF + 0.5f);
}


float ConvertFromDeviceZ(float DeviceZ)
{
    // Supports ortho and perspective, see CreateInvDeviceZToWorldZTransform()
    return DeviceZ * InvDeviceZToWorldZTransform[0] + InvDeviceZToWorldZTransform[1] + 1.0f / (DeviceZ * InvDeviceZToWorldZTransform[2] - InvDeviceZToWorldZTransform[3]);
}

float CalcSceneDepth(float2 ScreenUV)
{
    return ConvertFromDeviceZ(_GBuffer4.SampleLevel(pointClampSampler, ScreenUV, 0).r);
}

float4 GatherSceneDepth(float2 UV, float2 InvBufferSize)
{
    float2 TexelScale = 0.5f * InvBufferSize;
    return float4(
        CalcSceneDepth(UV + (float2(-1, 1) * TexelScale)),
        CalcSceneDepth(UV + (float2(1, 1) * TexelScale)),
        CalcSceneDepth(UV + (float2(1, -1) * TexelScale)),
        CalcSceneDepth(UV + (float2(-1, -1) * TexelScale))
        );
}

// can be moved/shared
half3 LookupSceneColor(float2 SceneUV, half2 PixelOffset)
{
    // faster
    return _CameraTexture.SampleLevel(pointClampSampler, SceneUV, 0, PixelOffset * View_BufferSizeAndInvSize.zw).rgb;
    //return SAMPLE_TEXTURE2D_X(_CameraTexture, sampler_PointClamp, SceneUV + PixelOffset * View_BufferSizeAndInvSize.zw).rgb;
}

bool CheckerFromSceneColorUV(float2 UVSceneColor)
{
    // relative to left top of the rendertarget (not viewport)
    uint2 PixelPos = (uint2)(UVSceneColor.xy * View_BufferSizeAndInvSize.xy).xy;
    uint TemporalAASampleIndex = 3;
    return (PixelPos.x + PixelPos.y + TemporalAASampleIndex) % 2;
}

SDiffuseAndSpecular ReconstructLighting(float2 UVSceneColor)
{
    SDiffuseAndSpecular Ret = (SDiffuseAndSpecular)0;

    bool bChecker = CheckerFromSceneColorUV(UVSceneColor);

    half3 Quant0 = _CameraTexture.SampleLevel(pointClampSampler, UVSceneColor, 0).rgb;
    //half3 Quant0 = SAMPLE_TEXTURE2D_X(_CameraTexture, sampler_PointClamp, UVSceneColor).rgb;

    half3 Quant1 = 0.5f * (
        LookupSceneColor(UVSceneColor, half2(1, 0)) +
        LookupSceneColor(UVSceneColor, half2(-1, 0)));

    Ret.Diffuse = lerp(Quant1, Quant0, bChecker);
    Ret.Specular = lerp(Quant0, Quant1, bChecker);
    return Ret;
}

// @param UVSceneColor for the full res rendertarget (BufferSize) e.g. SceneColor or GBuffers
// @return .RGB Color that should be scattared, .A:1 for subsurface scattering material, 0 for not
float4 SetupSubsurfaceForOnePixel(float2 UVSceneColor)
{
    float4 Ret = 0;

    //sample customdata to get material channel info 
    half packedChannel = _GBuffer1.SampleLevel(pointClampSampler, UVSceneColor, 0).a;
    uint ShadingModelID = ((uint)round(packedChannel * (float)0xFF)) & SHADINGMODELID_MASK;

    [branch]
    if (UseSubsurfaceProfile(ShadingModelID))
    {

        SDiffuseAndSpecular DiffuseAndSpecular = ReconstructLighting(UVSceneColor);

        Ret.rgb = DiffuseAndSpecular.Diffuse;

        // it's a valid sample
        Ret.a = 1;
    }

    return Ret;
}


float4 test(float2 UVSceneColor)
{
    float4 Ret = 0;

    //sample customdata to get material channel info 
    half packedChannel = _GBuffer1.SampleLevel(pointClampSampler, UVSceneColor, 0).a;
    uint ShadingModelID = ((uint)round(packedChannel * (float)0xFF)) & SHADINGMODELID_MASK;

    [branch]
    if (UseSubsurfaceProfile(ShadingModelID))
    {

        bool bChecker = CheckerFromSceneColorUV(UVSceneColor);

        Ret.rgb = bChecker;

        // it's a valid sample
        Ret.a = 1;
    }

    return Ret;
}

void AddSeparableGroup(uint2 GroupXY)
{
    //buffer counter is stored in the .Count in the first element.
    uint IndexToStore = 0;

    InterlockedAdd(RWSeparableGroupBuffer[0], 1, IndexToStore);  

    if (IndexToStore >= SubsurfaceUniformParameters_MaxGroupCount)
    {
        return;
    }

    RWSeparableGroupBuffer[2 * (IndexToStore + 1) + 0] = GroupXY.x;
    RWSeparableGroupBuffer[2 * (IndexToStore + 1) + 1] = GroupXY.y;
}


void AddSubsurfaceComputeGroup(uint GI, uint Type, uint2 GroupXY)
{
    InterlockedOr(SubsurfaceTypeFlag, Type);  

    GroupMemoryBarrierWithGroupSync();

    if (GI == 0 && (SubsurfaceTypeFlag & TYPE_SEPARABLE))
    {
        AddSeparableGroup(GroupXY);
    }

    if (GI == 0 && (SubsurfaceTypeFlag & TYPE_BURLEY)) //not support 
    {
        //AddBurleyGroup(GroupXY); //do nothing 
    }
}


[numthreads(1, 1, 1)]
void InitValueBufferCS()  //event name: InitGroupCounter
{
    RWSeparableGroupBuffer[0] = 0;    
}

[numthreads(1, 1, 1)]
void BuildIndirectDispatchArgsCS()  //event name: BuildBurleyIndirectDispatchArgs
{
    uint ValueCount = min(SubsurfaceUniformParameters_MaxGroupCount, GroupBuffer[0]);   
    RWIndirectDispatchArgsBuffer[0] = ValueCount;
    RWIndirectDispatchArgsBuffer[1] = 1;
    RWIndirectDispatchArgsBuffer[2] = 1;
}


RWTexture2D<float4> SetupTexture; // [2D RT 31731] Half Res 

//[numthreads(THREAD_SIZE_X, THREAD_SIZE_Y, 1)]   uint3 DT_ID : SV_DispatchThreadID,
[numthreads(8, 8, 1)]
void SetupIndirectCS(uint3 DT_ID : SV_DispatchThreadID, uint3 G_ID : SV_GroupID, uint3 GT_ID : SV_GroupThreadID, uint GI : SV_GroupIndex)
{
    if (GI == 0)
    {
        SubsurfaceTypeFlag = 0;
    }
    GroupMemoryBarrier();

    uint2 Pos = DT_ID.xy + Output_ViewportMinMax.xy;  
    //uint2 Pos = G_ID.xy * uint2(THREAD_SIZE_X, THREAD_SIZE_Y) + GT_ID.xy + Output_ViewportMinMax.xy;

    bool bHasSubsurface = false;
    float2 BufferUV = ConvertGridPos2UV(Pos);
    uint Type = 0;
    float4 OutColor = 0;

    //SetupTexture[Pos.xy] = float4(0, 0, 0, 0);  //clean up all  

    // --------------SUBSURFACE_HALF_RES START--------------
    // order aligned with Gather() hardware implementation
    // RGB: color*A, A:weight 0 if no subsurface scattering
    float4 A = SetupSubsurfaceForOnePixel(min(BufferUV + float2(-0.5, 0.5f) * SubsurfaceInput0_ExtentInverse.zw, SubsurfaceInput0_UVViewportBilinearMax.zw));
    float4 B = SetupSubsurfaceForOnePixel(min(BufferUV + float2(0.5, 0.5f) * SubsurfaceInput0_ExtentInverse.zw, SubsurfaceInput0_UVViewportBilinearMax.zw));
    float4 C = SetupSubsurfaceForOnePixel(min(BufferUV + float2(0.5, -0.5f) * SubsurfaceInput0_ExtentInverse.zw, SubsurfaceInput0_UVViewportBilinearMax.zw));
    float4 D = SetupSubsurfaceForOnePixel(min(BufferUV + float2(-0.5, -0.5f) * SubsurfaceInput0_ExtentInverse.zw, SubsurfaceInput0_UVViewportBilinearMax.zw));

    float4 Sum = (A + B) + (C + D);
    float Div = 1.0f / max(Sum.a, 0.00001f);
    OutColor.rgb = Sum.rgb * Div;

    float4 FourDepth = GatherSceneDepth(BufferUV, SubsurfaceInput0_ExtentInverse.zw);
    // average all valid depth values to a single one
    float SingleDepth = dot(FourDepth, float4(A.a, B.a, C.a, D.a)) * Div;

    OutColor.a = SingleDepth;

    if (OutColor.a > 0)
    {
        bHasSubsurface = true;  //? 
    }
    // --------------SUBSURFACE_HALF_RES END--------------

    Type = TYPE_SEPARABLE; // use separable for half resolution

    if (all(Pos < Output_ViewportMinMax.zw)) 
    {
        SetupTexture[Pos] = OutColor;
    }

    AddSubsurfaceComputeGroup(GI, Type, G_ID.xy);
}





// Create a RenderTexture with enableRandomWrite flag and set it
// with cs.SetTexture
RWTexture2D<float4> Result;

[numthreads(8, 8, 1)]
void CSMain(uint3 id : SV_DispatchThreadID)
{
    // TODO: insert actual code here!

    Result[id.xy] = float4(id.x & id.y, (id.x & 15) / 15.0, (id.y & 15) / 15.0, 0.0);
}


