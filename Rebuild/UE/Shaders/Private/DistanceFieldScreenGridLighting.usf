// Copyright Epic Games, Inc. All Rights Reserved.

/*=============================================================================
	DistanceFieldScreenGridLighting.usf
=============================================================================*/

#include "Common.ush"
#include "DeferredShadingCommon.ush"
#include "DistanceFieldLightingShared.ush"
#include "DistanceFieldAOShared.ush"
#include "GlobalDistanceFieldShared.ush"

/** Computes the distance field normal from the GBuffer. */
void ComputeDistanceFieldNormalPS(
	in float4 UVAndScreenPos : TEXCOORD0, 
	in float4 SVPos : SV_POSITION,
	out float4 OutColor : SV_Target0)
{
	// Sample from the center of the top left full resolution texel
	float2 ScreenUV = float2((floor(SVPos.xy) * DOWNSAMPLE_FACTOR + View.ViewRectMin.xy + .5f) * View.BufferSizeAndInvSize.zw);
	float SceneDepth = CalcSceneDepth(ScreenUV);
	FGBufferData GBufferData = GetGBufferData(ScreenUV);

	OutColor = EncodeDownsampledGBuffer(GBufferData, SceneDepth);
}

RWTexture2D<float4> RWDistanceFieldNormal;

[numthreads(THREADGROUP_SIZEX, THREADGROUP_SIZEY, 1)]
void ComputeDistanceFieldNormalCS(
	uint3 GroupId : SV_GroupID,
	uint3 DispatchThreadId : SV_DispatchThreadID,
    uint3 GroupThreadId : SV_GroupThreadID) 
{
	float2 ScreenUV = float2((DispatchThreadId.xy * DOWNSAMPLE_FACTOR + View.ViewRectMin.xy + .5f) * View.BufferSizeAndInvSize.zw);
	float SceneDepth = CalcSceneDepth(ScreenUV);
	FGBufferData GBufferData = GetGBufferData(ScreenUV);

	float4 OutValue = EncodeDownsampledGBuffer(GBufferData, SceneDepth);
	RWDistanceFieldNormal[DispatchThreadId.xy] = OutValue;
}

Buffer<float4> TileConeDepthRanges;
float TanConeHalfAngle;
RWBuffer<uint> RWScreenGridConeVisibility;
RWBuffer<float> RWConeDepthVisibilityFunction;

void HemisphereConeTraceAgainstTileCulledObjects(uint ObjectIndex, uint OutputBaseIndex, float3 WorldShadingPosition, float SceneDepth, float3 WorldNormal, float3 TangentX, float3 TangentY)
{
	float MaxWorldStepOffset = GetStepOffset(NUM_CONE_STEPS);  	//最大的射线距离 
	float InvMaxOcclusionDistance = 1.0f / AOObjectMaxDistance;

#if USE_GLOBAL_DISTANCE_FIELD
	InvMaxOcclusionDistance = 1.0f / AOGlobalMaxOcclusionDistance;
#endif

	float4 ObjectPositionAndRadius = LoadObjectPositionAndRadius(ObjectIndex);
	//物体到着色点的距离的平方 
	float ObjectDistanceSq = dot(ObjectPositionAndRadius.xyz - WorldShadingPosition, ObjectPositionAndRadius.xyz - WorldShadingPosition);

	BRANCH
	// Skip tracing objects with a small projected angle 
	// 简言之，物体球太小，距离太远的不考虑 
	if (ObjectPositionAndRadius.w * ObjectPositionAndRadius.w / ObjectDistanceSq > Square(.25f))
	{
		//CULLED_OBJECT_DATA_STRIDE = 17 
		float3 LocalPositionExtent = LoadObjectLocalPositionExtent(ObjectIndex);
		float4x4 WorldToVolume = LoadObjectWorldToVolume(ObjectIndex);
		bool bGeneratedAsTwoSided;
		//UV_Scale用于将Volume空间内的AABB包围盒边长缩放到采样空间内的该物体的AABB边长  
		//Volume_Scale则用于调整SDF采样数值，间接影响该物体形成AO的效果 
		float4 UVScaleAndVolumeScale = LoadObjectUVScale(ObjectIndex, bGeneratedAsTwoSided);
		//[重点]将着色点世界坐标变换到以Object为中心，以预烘焙的AABB在世界空间中的轴向为坐标轴的Volume_Space中去 
		//从而可知所有Object都是动态的，支持物体的translation + rotation，但是应该不支持scale，不然sdf数据将无法对齐 
		float3 VolumeShadingPosition = mul(float4(WorldShadingPosition, 1), WorldToVolume).xyz;
		//快速计算点到以原点为中心的BOX的距离 -> 注意里面使用了manhattan distance 
		float BoxDistance = ComputeDistanceFromBoxToPoint(-LocalPositionExtent, LocalPositionExtent, VolumeShadingPosition) * UVScaleAndVolumeScale.w;

		BRANCH
		if (BoxDistance < AOObjectMaxDistance)
		{
			//UVAdd.xyz -> 用于将针对Volume缩放后的采样点坐标移动到 512*512*512 体积的打包3D纹理的正确位置 
			float4 UVAddAndSelfShadowBias = LoadObjectUVAddAndSelfShadowBias(ObjectIndex);
			float2 DistanceFieldMAD = LoadObjectDistanceFieldMAD(ObjectIndex);

			float ObjectOccluderRadius = length(LocalPositionExtent) * .5f * UVScaleAndVolumeScale.w;
			float SelfShadowScale = 1.0f / max(UVAddAndSelfShadowBias.w, .0001f);

			LOOP
			for (uint ConeIndex = 0; ConeIndex < NUM_CONE_DIRECTIONS; ConeIndex++)  //沿9个朝向发射Ray 
			{
				//获取切斜空间朝向 
				float3 ConeDirection = AOSamples2.SampleDirections[ConeIndex].xyz;
				//经世界空间中构造的TBN矩阵，将射线朝向变换到WorldSpace中 
				float3 RotatedConeDirection = ConeDirection.x * TangentX + ConeDirection.y * TangentY + ConeDirection.z * WorldNormal;
				//进一步将朝向变换到Obj Volume Space中
				float3 ScaledLocalConeDirection = mul(RotatedConeDirection, (float3x3)WorldToVolume).xyz;
		
				float MinVisibility = 1;
				float WorldStepOffset = GetStepOffset(0);

				#if USE_GLOBAL_DISTANCE_FIELD
					WorldStepOffset += 2;
				#endif

				float CurrentStepOffset = WorldStepOffset;

				LOOP
				for (uint StepIndex = 0; StepIndex < NUM_CONE_STEPS && WorldStepOffset < MaxWorldStepOffset; StepIndex++)
				{
					//在Volume空间内，当前步进后光线端点的坐标 
					float3 StepSamplePosition = VolumeShadingPosition + ScaledLocalConeDirection * WorldStepOffset; 
					//利用Clamp，巧妙的获取到物体AABB表面上距离步进点最近的一点 (注:这里是投影距离，不是直线距离) 
					float3 ClampedSamplePosition = fastClamp(StepSamplePosition, -LocalPositionExtent, LocalPositionExtent);
					//计算步进点到AABB投影点之间的距离 
					float DistanceToClamped = lengthFast(StepSamplePosition - ClampedSamplePosition);
					// VolumePos * scale + offset -> 3D缩放和偏移，从而获得针对512^3立体纹理的采样坐标 
					float3 StepVolumeUV = DistanceFieldVolumePositionToUV(ClampedSamplePosition, UVScaleAndVolumeScale.xyz, UVAddAndSelfShadowBias.xyz);
					// 获得当前步进点距离目标物体的最近距离 
					float DistanceToOccluder = (SampleMeshDistanceField(StepVolumeUV, DistanceFieldMAD).x + DistanceToClamped) * UVScaleAndVolumeScale.w;

					float SphereRadius = WorldStepOffset * TanConeHalfAngle;  //Cone Tracing 中 Cone 的当前半径 
					float InvSphereRadius = rcpFast(SphereRadius);

					// Derive visibility from 1d intersection
					// Visibility定义为: 当前点到障碍物的距离 比上 当前点对应Cone的半径 
					float Visibility = saturate(DistanceToOccluder * InvSphereRadius);

					// Don't allow small objects to fully occlude a cone step
					// 物体越小， SmallObjectVisibility 越接近 1 
					float SmallObjectVisibility = 1 - saturate(ObjectOccluderRadius * InvSphereRadius);

					// Don't allow occlusion within an object's self shadow distance
					// SelfShadowBias 越大 SelfShadowScale 就越小 -> SelfShadowVisibility 就越接近 1 
					float SelfShadowVisibility = 1 - saturate(WorldStepOffset * SelfShadowScale);
					
					Visibility = max(Visibility, max(SmallObjectVisibility, SelfShadowVisibility));

					//加入距离淡出，当光线跑出去太远，同时也距离物体很远时，逐渐的将Visibility拉至1.0的水平 
					float OccluderDistanceFraction = (WorldStepOffset + DistanceToOccluder) * InvMaxOcclusionDistance;

					// Fade out occlusion based on distance to occluder to avoid a discontinuity at the max AO distance
					float DistanceFadeout = saturate(OccluderDistanceFraction * OccluderDistanceFraction * .6f);
					Visibility = max(Visibility, DistanceFadeout);
					MinVisibility = min(Visibility, MinVisibility);
					
					float MinStepScale = .6f;

					#if USE_GLOBAL_DISTANCE_FIELD
						MinStepScale = 2;
					#endif

					float NextStepOffset = GetStepOffset(StepIndex + 1);
					float MinStepSize = MinStepScale * (NextStepOffset - CurrentStepOffset);
					CurrentStepOffset = NextStepOffset;
					WorldStepOffset += max(DistanceToOccluder, MinStepSize);
				}

#if !PASS_THROUGH_DEBUG_VALUE
				// 非常有趣的发现: asuint(MinVisibility) -> 将浮点数保留bit pattern，直接当做uint来读取，你会发现当浮点数较小的，asuint到整型后任然较小！转换前后能保持数值上的比较顺序！ 
				InterlockedMin(RWScreenGridConeVisibility[ConeIndex * ScreenGridConeVisibilitySize.x * ScreenGridConeVisibilitySize.y + OutputBaseIndex], asuint(MinVisibility));
#endif
			}
		}
	}
}

Buffer<uint> CulledTileDataArray;

/** Traces cones of a hemisphere against intersecting object distance fields. */ 
[numthreads(CONE_TRACE_OBJECTS_THREADGROUP_SIZE, 1, 1)]  // ConeTraceObjectsThreadGroupSize = 64 
void ConeTraceObjectOcclusionCS(
	uint3 GroupId : SV_GroupID,
	uint3 DispatchThreadId : SV_DispatchThreadID,
    uint3 GroupThreadId : SV_GroupThreadID) 
{
	// PixelIndex = 0 ~ 15 -> 对应1个Tile内的pixel 
	uint PixelIndex = GroupThreadId.x % (CONE_TILE_SIZEX * CONE_TILE_SIZEX);  // CONE_TILE_SIZEX = 4 
	// SubCulledTileIndex = 0 ~ 3 -> 对应1个Group内的Tile数 
	uint SubCulledTileIndex = GroupThreadId.x / (CONE_TILE_SIZEX * CONE_TILE_SIZEX);
	// 每个 Group 有 64个线程 = 8x8 -> 对应了4个Tile 
	// CulledTileDataBaseIndex = 到当前Group为止，之前一共处理了多少个Culled Tile了  
	// [注意]GroupId.x "不"等于 0 ~ 54*30-1 -> 这里的GroupId总数越有2000+，是通过 ComputeCulledTilesStartOffsetCS 计算获取到的 
	// 对应了全部Object和它们影响到的Tile -> 所有GroupId总数 = ObjectNum * [(对应Obj影响到的Tile数 + 3) / 4] 
	uint CulledTileDataBaseIndex = GroupId.x * CONE_TRACE_TILES_PER_THREADGROUP; //CONE_TRACE_TILES_PER_THREADGROUP = 4 
	// 当前的 Culled Tile 索引 
	uint CulledTileIndex = CulledTileDataBaseIndex + SubCulledTileIndex; //只负责当前Group内的4个Tile即可 -> SubCulledTileIndex=0~3 
	// [注意]这里无需使用StartOffsetArray来获取偏移，因为GroupId本身就会遍历所有存放在CulledTileDataArray上的元素了 
	uint TileIndex = CulledTileDataArray[CulledTileIndex * CULLED_TILE_DATA_STRIDE + 0];  //此TileIndex可以对应到具体的屏幕UV 
	uint ObjectIndex = CulledTileDataArray[CulledTileDataBaseIndex * CULLED_TILE_DATA_STRIDE + 1]; 	//影响这个Tile的Obj 

	//转换到Tile分辨率[54,30]下的像素索引xy
	uint2 TileCoordinate = uint2(TileIndex % TileListGroupSize.x, TileIndex / TileListGroupSize.x); //TileListGroupSize.xy = [54,30]   
	//转换到Tile内部的索引xy 
	uint2 PixelCoordinate = uint2(PixelIndex % CONE_TILE_SIZEX, PixelIndex / CONE_TILE_SIZEX);
	//转换到Cone Tracing分辨率[213,120]下的当前Thread对应的像素索引xy 
	uint2 OutputCoordinate = TileCoordinate * CONE_TILE_SIZEX + PixelCoordinate;   

	//如果当前Tile是起到填充作用（补齐Group内空闲位置）的，那么它的对应TileIndex会被设置为INVALID -> 具体查看 ComputeCulledTilesStartOffsetCS 
	if (TileIndex != INVALID_TILE_INDEX && all(OutputCoordinate < ScreenGridConeVisibilitySize)) //ScreenGridConeVisibilitySize=[213, 120]
	{
		float2 BaseLevelScreenUV = GetBaseLevelScreenUVFromScreenGrid(OutputCoordinate); //转换到半分辨率(经过AO_DownSample的分辨率[854,480])后的uv 
		uint OutputBaseIndex = OutputCoordinate.y * ScreenGridConeVisibilitySize.x + OutputCoordinate.x; //光追分辨率像素的1维索引 

		float3 WorldNormal;
		float SceneDepth;
		GetDownsampledGBuffer(BaseLevelScreenUV, WorldNormal, SceneDepth); //采样获取对应深度和法线资源 

		float3 TangentX;
		float3 TangentY;
		FindBestAxisVectors2(WorldNormal, TangentX, TangentY); //计算切线和副切线 -> 从而构建出TBN矩阵 -> 解码光追9个规范朝向 

		{
			float2 ScreenUV = GetScreenUVFromScreenGrid(OutputCoordinate); //转换到全分辨率（屏幕分辨率[1708，960]）对应的uv 
			//  View.ScreenPositionScaleBias = [0.49971, -0.50, 0.50, 0.49971]
			float2 ScreenPosition = (ScreenUV.xy - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy;
		
			float3 WorldShadingPosition = mul(float4(ScreenPosition * SceneDepth, SceneDepth, 1), View.ScreenToWorld).xyz;

			HemisphereConeTraceAgainstTileCulledObjects(ObjectIndex, OutputBaseIndex, WorldShadingPosition, SceneDepth, WorldNormal, TangentX, TangentY);
		}

#if PASS_THROUGH_DEBUG_VALUE
		// Just increment for every tile / object intersection
		InterlockedAdd(RWScreenGridConeVisibility[OutputBaseIndex + 0], 1);
#endif
	}
}

//input: ClipmapIndex=具体使用的SDF数据；OutputBaseIndex=XY屏幕平面上，当前ScreenGrid的索引；
//			WorldShadingPosition=世界坐标；SceneDepth=场景深度；其余=世界空间中的TBN向量 
void HemisphereConeTraceAgainstGlobalDistanceFieldClipmap(
	uniform uint ClipmapIndex,
	uint OutputBaseIndex,
	float3 WorldShadingPosition,
	float SceneDepth,
	float3 WorldNormal,
	float3 TangentX,
	float3 TangentY)
{
	float MinStepSize = GlobalVolumeCenterAndExtent[ClipmapIndex].w * 2 / 300.0f; //最小光追步进与Volume的边长线性相关 
	float InvAOGlobalMaxOcclusionDistance = 1.0f / AOGlobalMaxOcclusionDistance; // 1 / 1000 
	float InitialOffset = GetStepOffset(NUM_CONE_STEPS);  //NUM_CONE_STEPS=10 -> 75.8 -> 对应0.75米 

	float ConeTraceLeakFill = 1.0f;
#if	!CONE_TRACE_OBJECTS
	// Without the object cone trace there is a lot of AO leaking. Constant initial offset looks worse, but helps with leaking.
	InitialOffset = GlobalVolumeCenterAndExtent[ClipmapIndex].w * GlobalVolumeTexelSize * 2.0f;

	// Cover AO leaking by comparing initial step SDF value against initial step size.
	{
		float3 WorldSamplePosition = WorldShadingPosition + WorldNormal * InitialOffset;
		float3 StepVolumeUV = ComputeGlobalUV(WorldSamplePosition, ClipmapIndex);
		float DistanceToOccluder = SampleGlobalDistanceField(ClipmapIndex, StepVolumeUV).x;
		ConeTraceLeakFill = saturate(Pow2(DistanceToOccluder / InitialOffset)) * 0.4f + 0.6f;
	}
#endif

	LOOP
	for (uint ConeIndex = 0; ConeIndex < NUM_CONE_DIRECTIONS; ConeIndex++) 	//NUM_CONE_DIRECTIONS=9 
	{	//对9个不同方向发射采样光线 
		float3 ConeDirection = AOSamples2.SampleDirections[ConeIndex].xyz;
		float3 RotatedConeDirection = ConeDirection.x * TangentX + ConeDirection.y * TangentY + ConeDirection.z * WorldNormal;

		float MinVisibility = 1;
		float WorldStepOffset = InitialOffset;

		LOOP
		for (uint StepIndex = 0; StepIndex < NUM_CONE_STEPS && WorldStepOffset < AOGlobalMaxOcclusionDistance; StepIndex++)
		{
			//Ray-marching 
			float3 WorldSamplePosition = WorldShadingPosition + RotatedConeDirection * WorldStepOffset;
			float3 StepVolumeUV = ComputeGlobalUV(WorldSamplePosition, ClipmapIndex); //世界坐标转换到GlobalVolume（AABB）局部坐标，再转换为局部uvw 
			float DistanceToOccluder = SampleGlobalDistanceField(ClipmapIndex, StepVolumeUV).x; 
			float SphereRadius = WorldStepOffset * TanConeHalfAngle;  //透射距离越远，Cone的半径越大 
			float InvSphereRadius = rcpFast(SphereRadius);

			// Derive visibility from 1d intersection
			// 以下是2个球(A和B)半径之比，球A半径代表当前点到最近物体的距离，球B半径代表光椎(cone)粗端的截面半径，球B的半径是一个用户可调节的值
			float Visibility = saturate(DistanceToOccluder * InvSphereRadius);
			
			// WorldStepOffset 与 DistanceToOccluder 之间的关系 -> 当表面没有遮挡物时，这两货数值应该趋近；当有遮挡物时 WorldStepOffset > DistanceToOccluder 
			// 取值范围： 0 ~ 2 -> 光线步进越远，数值大抵上会变得越大 
			float OccluderDistanceFraction = (WorldStepOffset + DistanceToOccluder) * InvAOGlobalMaxOcclusionDistance; 

			// Fade out occlusion based on distance to occluder to avoid a discontinuity at the max AO distance 
			// 翻译过来就是，让DFAO随着步进的增加而逐渐减弱，以避免在 Max AO Distance 处出现数值跳变的现象 
			Visibility = max(Visibility, saturate(OccluderDistanceFraction * OccluderDistanceFraction * .6f));	
			
			MinVisibility = min(MinVisibility, Visibility);

			WorldStepOffset += max(DistanceToOccluder, MinStepSize); //引入DistanceToOccluder以加速简单表面（往往Dist很大，不考虑地面的话）
		}

		MinVisibility *= ConeTraceLeakFill;

		#if PASS_THROUGH_DEBUG_VALUE
			//InterlockedAdd(RWScreenGridConeVisibility[OutputBaseIndex + 0], 1);
		#else
			// RWScreenGridConeVisibility 的结构 -> 一共有 NUM_CONE_DIRECTIONS=9 段，每一段存放 ScreenGrid=X*Y=213*120 总数个单位 
			// 每个存储单位 = 当前屏幕空间Grid所在区域，当前朝向上的可见性（Visibility） 
			InterlockedMin(RWScreenGridConeVisibility[ConeIndex * ScreenGridConeVisibilitySize.x * ScreenGridConeVisibilitySize.y + OutputBaseIndex], asuint(MinVisibility));
		#endif
	}
}

//input: OutputBaseIndex=XY屏幕平面上，当前ScreenGrid的索引； WorldShadingPosition=世界坐标； SceneDepth=场景深度；其余=世界空间中的TBN向量 
void HemisphereConeTraceAgainstGlobalDistanceField(uint OutputBaseIndex, float3 WorldShadingPosition, float SceneDepth, float3 WorldNormal, float3 TangentX, float3 TangentY)
{
#define USE_GLOBAL_CLIPMAPS 1
#if USE_GLOBAL_CLIPMAPS
	//计算当前点到 GlobalVolume (一个AABB) 表面的最短距离 -> AABB的边长为2500 * 2 -> 50米 
	float DistanceFromClipmap = ComputeDistanceFromBoxToPointInside(GlobalVolumeCenterAndExtent[0].xyz, GlobalVolumeCenterAndExtent[0].www, WorldShadingPosition);

	BRANCH
	if (DistanceFromClipmap > AOGlobalMaxOcclusionDistance) //AOGlobalMaxOcclusionDistance=1000 -> 10米 
	{	//该像素处于Volume的最中心区域（25-10=15米以内），决定使用LOD=0级别的SDF 
		HemisphereConeTraceAgainstGlobalDistanceFieldClipmap((uint)0, OutputBaseIndex, WorldShadingPosition, SceneDepth, WorldNormal, TangentX, TangentY);
	}
	else
	{
		//当前点距离LOD=0级别的AABB中心点较远(distance > 15米) 
		//使用LOD=1级别的AABB重新计算 DistanceFromClipmap -> AABB的边长为5000 * 2 -> 100米 
		DistanceFromClipmap = ComputeDistanceFromBoxToPointInside(GlobalVolumeCenterAndExtent[1].xyz, GlobalVolumeCenterAndExtent[1].www, WorldShadingPosition);

		BRANCH
		if (DistanceFromClipmap > AOGlobalMaxOcclusionDistance)
		{	//该像素处于Volume的最中心区域（50-10=40米以内），决定使用LOD=1级别的SDF 
			HemisphereConeTraceAgainstGlobalDistanceFieldClipmap((uint)1, OutputBaseIndex, WorldShadingPosition, SceneDepth, WorldNormal, TangentX, TangentY);
		}
		else
		{
			//还是太远，需要使用LOD=2级别的AABB -> AABB的边长为10000 * 2 -> 200米 
			DistanceFromClipmap = ComputeDistanceFromBoxToPointInside(GlobalVolumeCenterAndExtent[2].xyz, GlobalVolumeCenterAndExtent[2].www, WorldShadingPosition);
			//顺便计算LastVolume ->  AABB的边长为20000 * 2 -> 400米 
			float DistanceFromLastClipmap = ComputeDistanceFromBoxToPointInside(GlobalVolumeCenterAndExtent[3].xyz, GlobalVolumeCenterAndExtent[3].www, WorldShadingPosition);

			BRANCH
			if (DistanceFromClipmap > AOGlobalMaxOcclusionDistance) 
			{
				HemisphereConeTraceAgainstGlobalDistanceFieldClipmap((uint)2, OutputBaseIndex, WorldShadingPosition, SceneDepth, WorldNormal, TangentX, TangentY);
			}
			else if (DistanceFromLastClipmap > AOGlobalMaxOcclusionDistance)
			{
				HemisphereConeTraceAgainstGlobalDistanceFieldClipmap((uint)3, OutputBaseIndex, WorldShadingPosition, SceneDepth, WorldNormal, TangentX, TangentY);
			}
		}
	}
#else

	HemisphereConeTraceAgainstGlobalDistanceFieldClipmap((uint)0, OutputBaseIndex, WorldShadingPosition, SceneDepth, WorldNormal, TangentX, TangentY);

#endif
}

#ifndef CONE_TRACE_GLOBAL_DISPATCH_SIZEX
#define CONE_TRACE_GLOBAL_DISPATCH_SIZEX 1    // this equals 8 
#endif
 
//Dispatch(27,15,1) -> *[8,8,1] -> (213, 120, 1) -> 对于Full-Resolution[1708,960]来说，单维度=1/8，像素数为 1/(8*8) = 1/64 
//一个ScreenGrid -> 对应 64像素，长宽8X8 
/** */
[numthreads(CONE_TRACE_GLOBAL_DISPATCH_SIZEX, CONE_TRACE_GLOBAL_DISPATCH_SIZEX, 1)] //[8,8,1] 
void ConeTraceGlobalOcclusionCS(
	uint3 GroupId : SV_GroupID,
	uint3 DispatchThreadId : SV_DispatchThreadID,
    uint3 GroupThreadId : SV_GroupThreadID) 
{
	uint2 OutputCoordinate = DispatchThreadId.xy;
	
	if (all(OutputCoordinate < ScreenGridConeVisibilitySize))  //ScreenGridConeVisibilitySize=[213, 120] Grid的数目(对应屏幕空间的横向和纵向) 
	{
		float2 BaseLevelScreenUV = GetBaseLevelScreenUVFromScreenGrid(OutputCoordinate); //获得0-1的UV，且经过了Jitter和offset 

		float3 WorldNormal;
		float SceneDepth;
		GetDownsampledGBuffer(BaseLevelScreenUV, WorldNormal, SceneDepth); //采样DistanceFieldNormalTexture，获取WorldNormal和SceneDepth 

		float3 TangentX;
		float3 TangentY;
		FindBestAxisVectors2(WorldNormal, TangentX, TangentY); //使用世界空间向前(Z方向)向量 叉乘 WorldNormal，定义出TangentXY 

		float2 ScreenUV = GetScreenUVFromScreenGrid(OutputCoordinate); //从Grid Index映射到屏幕UV (对应Full-Resolution) 
		// (uv - 0.5) * 2 -> [-1, 1] -> ScreenPosition
		float2 ScreenPosition = (ScreenUV.xy - View.ScreenPositionScaleBias.wz) / View.ScreenPositionScaleBias.xy; 
		
		// 重建世界坐标 
		// float4(ScreenPosition * SceneDepth, SceneDepth, 1) 是一个标准的位于Clip空间中的点， 等于 NDC * Clip.w -> Clip Space Position 
		// 注意ScreenToWorld区别于Unity中的invViewProjMatrix，前者用于变换HClipSpace中的点，后者用于变换NDC中的点 
		float3 WorldShadingPosition = mul(float4(ScreenPosition * SceneDepth, SceneDepth, 1), View.ScreenToWorld).xyz;

		// 在XY轴向上铺开的ScreenGrid，当前CS对应了第几个Grid -> 这里输出的是一个索引 
		uint OutputBaseIndex = OutputCoordinate.y * ScreenGridConeVisibilitySize.x + OutputCoordinate.x; 
		//input: OutputBaseIndex=XY屏幕平面上，当前ScreenGrid的索引； WorldShadingPosition=世界坐标； SceneDepth=场景深度；其余=世界空间中的TBN向量 
		HemisphereConeTraceAgainstGlobalDistanceField(OutputBaseIndex, WorldShadingPosition, SceneDepth, WorldNormal, TangentX, TangentY);
	}
}

Buffer<uint> ScreenGridConeVisibility;
RWTexture2D<float4> RWDistanceFieldBentNormal;
uint2 ConeBufferMax;  //[212, 119] = [View.ViewRect.Width() / GAODownsampleFactor / GConeTraceDownsampleFactor - 1, View.ViewRect.Height() / GAODownsampleFactor / GConeTraceDownsampleFactor - 1]
float2 DFNormalBufferUVMax; //也是半分辨率下的UV最大值 (最后会空出半个像素的uv)

#ifndef COMBINE_CONES_SIZEX
#define COMBINE_CONES_SIZEX 1
#endif

/** */
[numthreads(COMBINE_CONES_SIZEX, COMBINE_CONES_SIZEX, 1)]
void CombineConeVisibilityCS(
	uint3 GroupId : SV_GroupID,
	uint3 DispatchThreadId : SV_DispatchThreadID,
    uint3 GroupThreadId : SV_GroupThreadID) 
{
	uint2 InputCoordinate = min(DispatchThreadId.xy, ConeBufferMax); 	//[0, 0] ~ [213, 120]
	uint2 OutputCoordinate = DispatchThreadId.xy;
	
	float2 BaseLevelScreenUV = GetBaseLevelScreenUVFromScreenGrid(InputCoordinate); //半分辨率下的UV
	BaseLevelScreenUV = min(BaseLevelScreenUV, DFNormalBufferUVMax);

	float3 WorldNormal;
	float SceneDepth;
	GetDownsampledGBuffer(BaseLevelScreenUV, WorldNormal, SceneDepth);

	float3 TangentX;
	float3 TangentY;
	FindBestAxisVectors2(WorldNormal, TangentX, TangentY);

	uint InputBaseIndex = InputCoordinate.y * ScreenGridConeVisibilitySize.x + InputCoordinate.x;

#if PASS_THROUGH_DEBUG_VALUE
	float BufferValue = ScreenGridConeVisibility[InputBaseIndex + 0] - asuint(1.0f);
	float DebugValue = BufferValue / 100.0f;
	RWDistanceFieldBentNormal[OutputCoordinate] = float4(DebugValue.xxx, SceneDepth);
#else
	float3 UnoccludedDirection = 0;
	
	for (uint ConeIndex = 0; ConeIndex < NUM_CONE_DIRECTIONS; ConeIndex++)
	{
		float ConeVisibility = asfloat(ScreenGridConeVisibility[ConeIndex * ScreenGridConeVisibilitySize.x * ScreenGridConeVisibilitySize.y + InputBaseIndex]);
		
		float3 ConeDirection = AOSamples2.SampleDirections[ConeIndex].xyz;
		float3 RotatedConeDirection = ConeDirection.x * TangentX + ConeDirection.y * TangentY + ConeDirection.z * WorldNormal;
		UnoccludedDirection += ConeVisibility * RotatedConeDirection;  //对9个方向权重求和 
	}

	float InvNumSamples = 1.0f / (float)NUM_CONE_DIRECTIONS;
	float3 BentNormal = UnoccludedDirection * (BentNormalNormalizeFactor * InvNumSamples);

	RWDistanceFieldBentNormal[OutputCoordinate] = float4(BentNormal, SceneDepth);
#endif
}